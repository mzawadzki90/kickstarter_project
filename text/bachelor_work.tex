%! Author = Michał_Komputer
%! Date = 14.10.2021

% Preamble
\documentclass[a4paper,11pt]{article}

% Packages
\usepackage[T1]{fontenc}
\usepackage[backend=bibtex,style=alphabetic]{biblatex}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{array}
\usepackage{enumerate}
\usepackage{float}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{latexsym}
\usepackage{mathtools}
\usepackage{placeins}
\usepackage{polski}
\usepackage{tabularx}


% Title page
\title{Optymalizacja hiperparametrów procesu uczenia sieci neuronowych z wykorzystaniem algorytmu genetycznego}
\author{Michał Zawadzki}
\date{Listopad 2021}


% Additial settings
\DeclareUnicodeCharacter{266D}{\includegraphics[height=1ex]{music_flat_sign}}
\DeclareUnicodeCharacter{266F}{\includegraphics[height=1ex]{music_sharp_sign}}
\addbibresource{references.bib}
\restylefloat{table}

% Document
\begin{document}

    \maketitle

    \tableofcontents


    \section{Wstęp}

    \subsection{Cel pracy}
    Korzystając ze zbioru danych o utworach muzycznych dostępnych na platformie streaming-owej Spotify, stworzono kilka modeli szacujących jaką popularność osiągnie na tej platformie nowy utwór. Modele te są prostymi sieciami neuronowymi o różnej architekturze. Do optymalizacji ich hiperparametrów uczenia wykorzystano algorytm genetyczny.

    \subsection{Teza główna} % uwaga od promotora: jeżeli piszesz tezę to musi być ona znacznie bardziej konkretna, musi opisywać coś mierzalnego
    Algorytm genetyczny może znacząco przyspieszyć proces wyboru optymalnych hiperparametrów uczenia dla wstępnie zaprojektowanej sieci neuronowej.

    \subsection{Słowa kluczowe} % między 5 a 10

    \subsection{Abstrakt} % bardzo skondensowane streszczenie pracy z użyciem słów kluczowych


    \section{Wpływ cech utworów muzycznych na popularność}

    Zaczynając rozważania nad przyczynami, które sprawiają, że niektóre utwory muzyczne osiągają ogromną popularność, podczas gdy inne nie zdobywają uznania szerokiego audytorium, trzeba najpierw zdefiniować podstawowe czynniki jakimi kieruje się odbiorca przy dokonywaniu wyborów muzycznych. Magdalena Parus-Jankowska i Szymon Nożyński w swojej pracy ``Preferencje Muzyczne w Dobie Popularności Strumieniowego Słuchania Muzyki''\cite{PreferencjeMuzyczneWCzasachSteamingu2020} wymieniają 3 takie czynniki:
    \begin{itemize}
        \item \textit{upodobania} - Przywiązanie do konkretnych gatunków muzycznych, wraz z otaczającym je kontekstem kulturowym.
        \item \textit{smak/gust} - Umiejętność dostrzegania i oceny poszczególnych elementów składowych utworu, także znajomość i zrozumienie przesłania utworu.
        \item \textit{preferencje} - Upodobanie dla konkretnych utworów lub twórców muzycznych.
    \end{itemize}

    \smallskip

    Czynniki te często kształtują się równolegle i przenikają znaczeniowo, dlatego też dla uproszczenia w dalszej części posłużono się szeroko rozumianym pojęciem preferencji muzycznych.

    \bigskip

    Preferencje muzyczne człowieka nie są czymś stałym. Zmieniają się one przez całe życie, szczególnie intensywnie w wieku dziecięcym i w okresie dojrzewania\cite{PreferencjeMuzyczneWCzasachSteamingu2020}.Wielki wpływ na sposób konsumpcji treści muzycznych ma środowisko, z którego człowiek się wywodzi, jego wykształcenie, zamożność, światopogląd i osobowość\cite{PreferencjeMuzyczneWCzasachSteamingu2020}. Muzyki słuchają najczęściej ludzie młodzi (w grupie wiekowej 18-24 lata 77\% deklarowało słuchanie muzyki codziennie\cite{cbos2018}) i to oni pośrednio, a bezpośrednio wywodzący się z tej grupy twórcy, kształtują nowe trendy i czynią rynek muzyczny bardzo dynamicznym.

    \bigskip

    Wejście na rynek serwisów streaming-owych, których sztandarowym przykładem jest szwedzki gigant Spotify, dokonało małej rewolucji na rynku muzycznym. Serwis działa w dwóch modelach płatności: bezpłatnym (z reklamami) i subskrypcyjnym. Można korzystać z niego za pośrednictwem przeglądarki, ale dostępne są także dedykowane aplikacje ma praktycznie każdą platformę, zaczynając od smart car-u na smartfonie kończąc, między którymi można się swobodnie przełączać. Muzyki można słuchać zarówno w trybie online, jak i w trybie offline (oczywiście po wcześniejszym pobraniu na urządzenie). Co ważne zmianie uległ sposób konsumpcji samych treści. Autor niniejszej pracy, jako szczególnie aktywny użytkownik serwisu (być może bardziej adekwatnym określeniem byłaby platforma) uznał za stosowne wymienienie następujących alternatywnych kanałów:
    \begin{itemize}
        \item \textit{strona główna (ang. home)} - Najmocniej promowane przez serwis treści, również spersonalizowane sekcje z dedykowanymi playlistami, a także szybki dostęp do treści ostatnio odtwarzanych.
        \item \textit{radio wykonawcy, radio utworu} - Pseudo-radio, a właściwie strumień muzyczny generowany przez algorytm Spotify dla danego wykonawcy lub konkretnego utworu muzycznego
        \item \textit{aktywność znajomych} - Trzeba nadmienić, że Spotify jest też serwisem społecznościowym. Mamy wgląd w bieżącą aktywność znajomych (o ile słuchają muzyki w trybie sesji publicznej).
        \item \textit{playlisty publiczne} - Playlisty stworzone przez pracowników serwisu, algorytmy oraz członków społeczności. Równolegle do klasycznego podziału na gatunki muzyczne, serwis proponuje także bardziej utylitarne kategorie, jak na przykład muzykę dobrą do ćwiczeń, czytania czy wyciszenia się przed snem.
        \item \textit{playlisty prywatne} - Playlisty stworzone przez użytkownika, nieupublicznione.
        \item \textit{biblioteka} - Treści pobrane przez użytkownika.
    \end{itemize}

    \bigskip

    Wewnętrzna polityka serwisów muzycznych w zakresie promowania i pozycjonowania treści (w którą niestety nie ma wglądu, a która z ogromną dozą prawdopodobieństwa dyktowana jest przede wszystkim chęcią powiększania zasięgów i poprawy wyników finansowych) ma niebagatelny wpływ na wybory dokonywane przez użytkowników\cite{PreferencjeMuzyczneWCzasachSteamingu2020}. Zdaniem autora niniejszej pracy szczególnie duże znaczenie w tym aspekcie mają kryteria, na których oparty jest mechanizm wyszukiwania, a także (a może przede wszystkim) aspekt losowania kolejnych utworów w usłudze \textit{radio}. Z drugiej strony prawdziwe zdaje się być twierdzenie, że dobra muzyka obroni się sama. Bez względu na to jak bardzo konsument będzie zasypywany promowanymi treściami i tak regularnie będzie wracać tylko do tego co najbardziej trafiło w jego gusta.

    \bigskip

    Christoph Dr{\"o}sser, popularny w Niemczech dziennikarz popularnonaukowy, napisał ``Muzyka jest [\ldots] doświadczeniem całościowym, w znacznym stopniu nierozsądnym, którego nie da się ogarnąć za pomocą zimnego, racjonalnego instrumentarium nauki''\cite{MuzykaDajSieUwiesc2021}. Ale czy to aby na pewno prawda? Na początku 20-go wieku w mainstreamie zaczęło funkcjonować pojęcie \textit{Hit Song Science} (pl. nauka o przebojach muzycznych), za którego twórcę i głównego promotora uważa się Mike'a McCready\cite{HitSongScienceWiki}. McCready wraz ze współpracownikami, działając w ramach firmy Polyphonic HMI, starał się rozwijać i sprzedawać wytwórniom muzycznym narzędzia, oparte o techniki \textit{MIR} (music information retrieval, pl. pozyskiwanie informacji muzycznych z utworu) i \textit{data science}, ułatwiające przewidywanie czy dany utwór ma szanse stać się 'hitem'\cite{PolyphonicHMIWiki}. Odnośnie podstaw naukowych \textit{Hit Song Science} od lat, w szczególności w społeczności \textit{MIR}, toczy się burzliwa, nierozstrzygnięta do końca debata\cite{HitSongScienceWiki}.

    \bigskip

    François Pachet i Pierre Roy z firmy Sony Computer Science Laboratories, Inc. w artykule ``Hit Song Science Is Not Yet a Science'' z 2009-go roku\cite{HitSongScienceNotYet2009} opisują swoją nieudaną próbę stworzenia klasyfikatora szacującego popularność utworów na podstawie ich cech muzycznych oraz subiektywnych `ludzkich' etykiet przypisanych przez profesjonalnych ankieterów. Danymi, na których pracowali była baza 32978 dostarczona przez firmę HiFind. W swoim eksperymencie oprócz zaawansowanych technik \textit{MIR} wykorzystali oni \textit{Support Vector Machine} (pl. maszyna wektorów nośnych). Wyniki uzyskane dla poszczególnych prób tylko nieznacznie różniły się od losowych. Za przyczynę niepowodzenia uznano niewłaściwy dobór zestawu parametrów użytych do stworzenia modelu.

    \bigskip

    O wiele bardziej obiecujące wyniki uzyskali Yizhao Ni, Raúl Santos-Rodríguez, Matt Mcvicar i Tijl De Bie z kooperacji uniwersytetów University of Bristol i Universidad Carlos III de Madrid. W swoim artykule ``Hit Song Science Once Again a Science?'' z 2011-go roku\cite{HitSongScienceOnceAgain2011} (już poprzez sam tytuł ustawiając się w kontrapunkcie do poprzedników) przedstawiają wyniki swojego eksperymentu przeprowadzonego na zbiorze 5947 utworów z brytyjskiej listy przebojów z lat 1960-2010. Do ekstrakcji wartości parametrów muzycznych wykorzystali oni narzędzie EchoNest. Jako model wykorzystani oni prosty ruchomy perceptron (ang. \textit{Shifting perceptron}) będący funkcją czasu. Wyniki eksperymentów tym razem różniły się znacząco na korzyść w porównaniu do odczytów losowych. Badaczom udało się też sformułować na ich podstawie szereg cennych wniosków.

    \bigskip

    Wychodząc z założenia, że na przestrzeni ostatniej dekady nastąpił ogromny postęp w dziedzinie data science, w szczególności w obszarze badań nad głębokimi sieciami neuronowymi, a także (co nie mniej istotne) dostępne są ogromne bazy zawierające wysokiej jakości, świetnie ustandaryzowane i udokumentowane dane udostępnione przez serwisy muzyczne takie jak Spotify, autor niniejszej pracy z dużym entuzjazmem postanowił podjąć się samodzielnej próby stworzenia wysokiej klasy modelu do predykcji popularności utworów muzycznych.


    \section{Wykorzystanie sieci neuronowych do problemu regresji dla tabelarycznego zbioru danych}

    \subsection{Sztuczne sieci neuronowe a biologia}

    \subsection{Pierwsze implementacje sztucznych sieci neuronowych}

    \subsection{Uczenie wielowarstwowych sieci przy użyciu propagacji wstecznej}


    \section{Algorytmy Genetyczne}

    \subsection{Algorytm genetyczny a teoria ewolucji}

    Algorytm genetyczny powstał głównie jako odpowiedź na wyzwania obliczeniowe, do których trudno było podejść korzystając z tradycyjych narzędzi matematycznych. Czerpie on garściami inspiracje z teorii ewolucji i ogólnej wiedzy o genetyce. Już w 1948 Alan Turing zaproponował koncepcję `ewolucyjnego poszukiwania' (ang. \textit{evolutionary search}). Od lat 60-tych XX wieku podobne prace prowadzony był już w wielu ośrodkach\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    Teoria ewolucji Darwina wyjaśnia mechanizmy leżące u podstaw biologicznej różnorodności. To właśnie Darwin, badając fenotypy (cechy zewnętrzne) fauny i flory na wyspie Galapagos, dostrzegł że gatunki ewoluują, to jest dostosowują się do otoczenia, a głównej mierze opiera się to na selekcji naturalnej, czyli zdolności przetrwania w danym środowisku i znalezieniu partnera do prokreacji. Selekcja naturalna jest brutalna - wygrywa przeważnie najlepiej dopasowany. Innym ważnym czynnikiem odkrytym przez Darwina (oczywiście jedynie pośrednio, poprzez obserwacje zmian w fenotypie) są mutacje, czyli zmiany genetyczne przekładające się na zmiany w fenotypie, wprowadzające element losowości. Ewolucja nie jest równocześnie jednokierunkowym procesem optymalizacyjnym prowadzącym do `globalnego optimum'. W środowisku naturalnym oddziaływuje na siebie ogromna liczba czynników i może się zdarzyć, że najlepiej dopasowany osobnik zginie, albo że globalny, wysoki wskaźnik dopasowania dla całej populacji stanie się powodem jej upadku (na przykład poprzez wyparcie z ekosystemu gatunku zależnego, położonego niżej w łańcuchu pokarmowym)\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    \begin{figure}[H]
        \label{fig:darwin_birds}
        \centering
        \includegraphics[width=10cm]{darwin_birds}
        \caption{Darwin pracując na Galapagos prowadził między innymi badania nad różnicami w fenotypie zięb. Autor ilustracji: John Gould (`Voyage of the Beagle').}
    \end{figure}

    \bigskip

    Za ojca genetyki uważany jest Gregor Johann Mendel - niemiecko-czeski zakonnik działający w drugiej połowie XIX wieku. To on, prowadząc eksperymenty z krzyżowaniem roślin, odkrył zjawisko cech dominujących i recesywnych (w dzisiajszym spojrzeniu allelów dominujących i regresywnych). Podstawową jednostką przechowującą informację genetyczną jest gen. Konkretna wartość genu to allel. Jeden gen może mieć wpływ na wiele cech fenotypowych, jak i jedna cecha fenotypowa może być zdefiniowana przez wielę genów. Zmiany w fenotypie są zawsze uzależnione od zmian genetycznych, które z kolei są wynikiem mutacji i rekombinacji (krzyżówki materiału genetycznego rodziców). Genom jest komletną informacją genetyczną osobnika. Genom jest przechowywany w zestawie chromosomów (materiał genetyczny człowieka jest zapisany w 46 chromosomach). Wyższe formy życia (w tym oczywiście ludzie) przechowują podwójną kopię informacji genetycznej w większości komórek - nazywanych diploidami. Gamety, czyli komórki rozrodcze, zawierają jedynie pojedynczy zestaw chromosomów. Połączenie gamety męskiej z żeńską prowadzi do powstania zygoty. Proces ten określa się terminem ontogenezy. Podczas ontogenezy materiał genetyczny nie jest zmieniamy, dlatego nie można przyrównywać tego procesu do krzyżówki znanej z algorytmu genetycznego. Podobny do krzyżówki, jest z koleji proces formowania się gamet - mejoza - szczególny rodzaj podziału komórkowego, który gwarantuje, że w wynikowym produkcie - gamecie - znajdzie się tylko jedna kopia każdego z chromosomów. Na jednym z etapów mejozy ma również miejsce rekombinacja, a mówiąc precyjniej - krzyżówka w losowym punkcie przecięcia. Każda z czterech gamet powstałych w wyniku mejozy ma inną informacje genetyczną od oryginalnego genomu męskiego i żęskiego, co potem przekłada się na różnice genetyczne u potomków\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    \begin{figure}[H]
        \label{fig:punnett_squre_mendel}
        \centering
        \includegraphics[width=7cm]{punnett_squre_mendel}
        \caption{Szachownica Punnetta ilustruje dziedziczenie w przypadku dominacji zupełnej cechy jednogenowej. Autor: Madprime (Wikipedia Community).}
    \end{figure}

    \bigskip

    Niezmiernie ważne jest, by uświadomić sobie, że wszyskie zmiany (to jest mutacje i rekombinacje) zachodzą na poziomie genetycznym, natomiast selekcja naturalna odbywa się w oparciu o fenotyp\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    Komputerowe algorytmy genetyczne nie są odzworowaniem `jeden do jednego' procesów biologicznych, a jedynie się nimi inspirują. Terminologia używana w obu tych domenach jest często podobna, ale znaczenia poszczególnych terminów mogą być całkowicie odmienne. Zasadniczo, najważniejszym wspólnym mianowkiem jest koncepcja selekcji naturalnej, warunkująca dobieranie osobników do rekombinacji i wyznaczanie ocalałych (ang. \textit{survivors}).

    \subsection{Cykl życia populacji}

    Algorytm genetyczny jest z założenia generyczny - trzeba go traktować jako szablon, w którym w zależności od potrzeb można wymieniać komponenty składowe. Te kompomenty to:
    \begin{itemize}
        \item inicjacja populacji
        \item ewaluacja osobników
        \item selekcja rodziców
        \item rekombinacja/krzyżowanie
        \item mutacja
        \item wybór ocalałych
        \item warunek końcowy
    \end{itemize}

    \bigskip

    Wspólnym mianownikiem wszystkich algorytmów genetycznych jest populacja osobników (potencjalnych rozwiązań) funkcjonująca w środowisku o ograniczonych zasobach (ograniczenia dla poszczególnych parametrów), gdzie rządzi prawo selekcji naturalnej - przeżywają osobniki najlepiej dopasowane (z najlepszą wartością metryki dopasowania)\cite{IntroductionToEvolutionaryComputing2015}. W przypadku prawidłowo działającego algorytmu obserwujemy ciągłą poprawę średniej wartości metryki dopasowania w ujęciu pokoleniowym. W głównej mierze do poprawy wyników przyczynia się mechanizm selekcji. Mutacja i rekombinacja (krzyżówka) wprowadzają z kolei element losowości, zapewniając lepsze pokrycie przestrzeni potencjalnych rozwiązań.

    \bigskip

    Poniżej przedstawiono pseudokod dla algorytmu genetycznego oraz diagram ilustrujący cykl życia populacji.

    \smallskip

    \begin{algorithm}[H]
        \label{alg:genetic_algorithm_template}
        \caption{Generyczny szablon dla algorytmu genetycznego. Źródło:\cite{IntroductionToEvolutionaryComputing2015}.}
        \begin{algorithmic}
            \State INICJACJA POPULACJI LOSOWYMI OSOBNIKAMI
            \State EWALUACJA OSOBNIKÓW
            \While{NIE SPEŁNIENIE WARUNKU KOŃCOWEGO}
                \State WYBÓR RODZICÓW
                \State KRZYŻOWANIE RODZICÓW
                \State MUTACJA POTOMKÓW
                \State EWALUACJA POTOMSTWA
                \State WYBÓR OSOBNIKÓW DO NASTĘPNEGO POKOLENIA
            \EndWhile
            \State \Return NAJLEPSZY OSOBNIK
        \end{algorithmic}
    \end{algorithm}

    \bigskip

    \begin{figure}[H]
        \label{fig:genetic_algoritm_diagram}
        \centering
        \includegraphics[width=\textwidth]{genetic_algoritm_diagram}
        \caption{Cykl życia populacji w algorytmie genetycznym. Źródło:\cite{IntroductionToEvolutionaryComputing2015}}
    \end{figure}

    \subsection{Wybór rodziców}

    Selekcja rodziców (ang. \textit{parents}) ma na celu dobór najodpowiedniejszych osobników do rekombinacji (krzyżówki). Tak samo jak wybór ocalałych (ang. \textit{survivors}) wymusza ogólną poprawę jakości populacji. W algorytmach genetycznych selekcja rodziców oparta jest najczęściej na prawdopodobieństwie, gdzie osobniki z wysoką wartością metryki dopasowania mają największe szanse na wybór. Niemniej, osobniki gorsze również mają niewielkie szanse na bycie wyznaczonym. Powodem jest chęć zmiejszenia `zachłanności' algorytmu (ang. \textit{greedy algorithm}) i tym samym minimalizacja ryzyka wpadnięcia w optimum lokalne\cite{IntroductionToEvolutionaryComputing2015}.

    \subsection{Krzyżówki}

    Krzyżówka jest operacją pozwalającą na rekombinacje materiału genetycznego dwóch lub więcej osobników (rodziców, ang. \textit{parents}) w celu powołania do życia potomstwa (ang. \textit{offsprings}), które odziedziczy unikalną kombinację ich cech. Główną motywacją operacji krzyżowania jest chęć uzyskania przynajmniej jednego potomka, który osiągnie lepszą wartość metryki dopasowania od swoich rodziców\cite{GeneticAlgorithmEssentials2017}.

    \bigskip

    W praktyce stosowane są różne rodzaje rekombinacji: warianty z dwoma (najczęściej) lub z większą liczbą rodziców, krzyżówki jedno i wielopunktowe, dolosowywanie kolejnych cech od poszczególnych rodziców z określonym współczynnikiem prawdopodobieństwa. Trzeba pamiętać, że zastosowanie każdego z wymienionych wariantów niesie za sobą określone konsekwencje. Gdy pewne cechy są ze sobą powiązane warto rozważyć wariant z punktem przecięcia. W przypadku gdy konieczne jest zagwarantowanie określonych proporcji udziału rodziców w wynikowym materiale genetycznym potomka, zasadne jest rozważanie wariantu opartego o dolosowywanie z współczynnkiem prawdopodobieństwa\cite{IntroductionToEvolutionaryComputing2015}.

    \subsection{Mutacje}

    Mutacja ma na celu dostarczenie do populacji mutantów - osobników, których materiał genetyczny nie jest wyłącznie kombinacją genów rodzićów. Jest to swoisty dopływ `świeżej krwi', gwarantujący pełniejsze przeszukanie przestrzeni rozwiązań. Operator mutacji jest z założenia stochastyczny (losowy). Należy wystrzegać się przy jego implementacji jakichkolwiek elementów systemowych czy obciążeń (ang. \textit{bias}). Czysto teoretycznie prawidłowo zaimplementowana operacja mutacji gwarantuje osiągnięcie optimum globalnego w skończonym czasie\cite{IntroductionToEvolutionaryComputing2015}.

    \subsection{Wybór potomstwa}


    \section{Opis zbioru danych}

    Zbiór danych zawiera informacje o ponad 170 tysiącach utworów muzycznych, opublikowanych w latach 1921-2020 i dostępnych na szwedzkiej platformie streaming-owej Spotify. Dataset został stworzony przy wykorzystaniu oficjalnego, publicznego API deweloperskiego Spotify i udostępniony na platformie Kaggle w formacie CSV przez użytkownika Yamaç Eren Ay\cite{SpotifyKaggleDataset2020}.

    \bigskip

    Oryginalny dataset to zbiór tabelaryczny zawierający 170653 rekordów podzielonych na 19 kolumn. Kolumny te to kolejno:
    \begin{itemize}
        \item \textit{valence} (pl.ozdobnik) - Miara w skali od 0.0 do 1.0 określająca stopień `pozytywności' przekazywany przez utwór. Utwory z wysoką wartością współczynnika \textit{valence} brzmią bardziej pozytywnie (szczęśliwie, radośnie lub euforycznie), podczas gdy niska wartość tego współczynnika objawia się brzmieniem negatywnym (smutnym, depresyjnym, zdenerwowanym lub wściekłym).
        \item \textit{year} (pl. rok) - Rok publikacji utwory. Wartości między 1921 a 2020 włącznie.
        \item \textit{acousticness} (pl. akustyczność) - Miara w skali od 0.0 do 1.0 określająca pewność, z jaką dany utwór można zakwalifikować jako akustyczny. 1.0 - wskazuje na wysoką pewność, 0.0 na bardzo niską.
        \item \textit{artists} (pl. artyści) - Lista imion i nazwisk lub pseudonimów artystycznych artystów wykonujących dany utwór.
        \item \textit{danceability} (pl. taneczność) - Miara w skali od 0.0 do 1.0 określająca, w jakim stopniu dany utwór jest odpowiedni do tańca, wyliczana jako kombinacja takich parametrów muzycznych ja tempo, stabilność rytmu, moc taktu i ogólna regularność. 1.0 oznacza wysoką taneczność, a 0.0 - bardzo niską.
        \item \textit{duration\_ms} (pl. czas trwania) - Czas trwania utworu w milisekundach.
        \item \textit{energy} (pl. energia) - Miara w skali od 0.0 do 1.0 reprezentująca odczuwalny stopień intensywności i aktywności utworu. Typowy utwory `energetyczne' są odbierane jako szybkie, głośne czy wręcz hałaśliwe. Przykładem wysokiej energetyczności mogą byś utwory death-metalowe, podczas gdy preludia Bacha będą cechowały się niską energetycznością. Postrzegalne czynniki wpływające na tą cechę to dynamiczny zakres, odbierana głośność, tembr, \textit{onset rate} (pl. współczynnik rozpoczęć ??) i ogólna entropia.
        \item \textit{explicit} (pl. odważny/śmiały) - Wartość \textit{true} (pl. prawda)/\textit{false} (pl. fałsz). Flaga określająca czy dany utwór zawiera wulgaryzmy, treści erotyczne, treści nacechowane przemocą, wzmianki o nielegalny używkach i tym podobne; w ogólności treści skierowane do odbiorców pełnoletnich.
        \item \textit{id} (pl. identyfikator) - Unikalne, alfanumeryczne Spotify ID dla utworu.
        \item \textit{instrumentalness} (pl. instrumentalność) - Miara prawdopodobieństwa określająca, czy dany utwór nie zawiera wstawek wokalnych (fragmentów śpiewanych). Wyrazy dźwiękonaśladowcze takie jak `ooh' czy `aah' przez algorytm/klasyfikator są traktowane jako instrumentalne. Rap czy zwykła mowa traktowana jako `czysty wokal'. In bliżej wartości parametru \textit{instrumentalness} do wartości 1.0, tym wyższe prawdopodobieństwo braku wokali. Wartości powyżej 0.5 w założeniu mają reprezentować utwory instrumentalne, natomiast prawdopodobieństwo prawidłowej klasyfikacji rośnie wraz ze zbliżaniem się wskaźnika do wartości 1.0.
        \item \textit{key} (pl. tonacja). Tonacja utworu przedstawiona jako liczba całkowita nieujemna: 0,1,2\ldots . Liczby zmapowane są na standardową notację muzyczną: 0 = C, 1 = G, 2 = D i tak dalej.
        \item \textit{liveness} - (pl. żywość/żywiołowość) - Miara żywiołowości określa prawdopodobieństwo obecność publiczności podczas nagrania. Wartości \textit{liveness} powyżej 0.8 wskazują na wysokie prawdopodobieństwo, że utwór wykonywany był `na żywo'.
        \item \textit{loudness} (pl. głośność) - Ogólna głośność utworu mierzona w decybelach. Wartości głośności są wyliczane poprzez uśrednienie głośności całego utworu, co sprawia, że metryka staje się użyteczna do porównywania utworów. Głośność jest cechą dźwięku ściśle skorelowaną z amplitudą fali dźwiękowej. Wartości w większości przypadków wahają się między -60 a 0 db.
        \item \textit{mode} (pl. tryb/dominanta) - Parametr 'mode' oznacza modalność utworu: \textit{major} (pl. główna, pierwszorzędna) lub \textit{minor} (pl. pomniejsza, drugorzędna), w znaczeniu typu skali, w której znajduje się warstwa melodyczna. 1 oznacza \textit{major}, 0 to \textit{minor}.
        \item \textit{name} (pl. nazwa) - Tytuł piosenki, utworu lub nagrania.
        \item \textit{popularity} (pl. popularność) - Popularność utworu w skali od 0 do 100, gdzie 100 oznacza najwyższą popularność. Popularność wyliczana jest przez algorytm, bazujący przede wszystkim na liczbie odtworzeń utworu, ale także na tym jak świeże (odległe od chwili obecnej) są te odtworzenia.
        \item \textit{release\_date} (pl. data publikacji) - Data publikacji utworu lub albumu, na którym znalazł się utwór.
        \item \textit{speechiness} (pl. wypełnienie mową) - Parametr \textit{speechiness} określa stopień obecności mowy w utworze. Nagrania wypełnione mową takie jak programy `talk show', audiobooki czy poematy będą uzyskiwały wartości tego parametru zbliżone do 1.0. Wartości powyżej 0.66 wskazują na wysokie prawdopodobieństwo wypełnienia nagrania w całości mową. Wartości od 0.33 do 0.66 wskazują na występowanie zarówno mowy jak i muzyki, zarówno w następujących po sobie sekwencjach, jak i w nakładających się na siebie warstwach dźwiękowych. Wartości poniżej 0.33 oznaczają duże prawdopodobieństwo nie występowania mowy w utworze.
        \item \textit{tempo} (pl. tempo) - Ogólne szacowane tempo utworu w taktach na minutę (ang. \textit{BPM}). W terminologi muzycznej, tempo jest szybkością danego fragmentu/kawałka utworu wyliczaną bezpośrednio w oparciu o średnią długość taktu.
    \end{itemize}

    \smallskip

    Opisy parametrów są luźnym tłumaczeniem oficjalnej dokumentacji API deweloperskiego Spotify\cite{SpotifyWebAPIReference}. Metoda wyznaczania własności subiektywnych jest własnością intelektualną firmy Spotify i nie jest dostępna publicznie.

    \bigskip

    \begin{figure}[H]
        \label{fig:valence}
        \centering
        \includegraphics[width=\textwidth]{valence}
        \caption{Histogram dla cechy \textit{valence} (pl. ozdobnik).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:acousticness}
        \centering
        \includegraphics[width=\textwidth]{acousticness}
        \caption{Histogram dla cechy \textit{acousticness} (pl. akustyczność).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:danceability}
        \centering
        \includegraphics[width=\textwidth]{danceability}
        \caption{Histogram dla cechy \textit{danceability} (pl. taneczność).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:duration_ms}
        \centering
        \includegraphics[width=\textwidth]{duration_ms}
        \caption{Histogram dla cechy \textit{duration\_ms} (pl. czas trwania w milisekundach).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:energy}
        \centering
        \includegraphics[width=\textwidth]{energy}
        \caption{Histogram dla cechy \textit{energy} (pl. energia/energetyczność).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:instrumentalness}
        \centering
        \includegraphics[width=\textwidth]{instrumentalness}
        \caption{Histogram dla cechy \textit{instrumentalness} (pl. instrumentalność).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:liveness}
        \centering
        \includegraphics[width=\textwidth]{liveness}
        \caption{Histogram dla cechy \textit{liveness} (pl. żywość/żywiołowość).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:loudness}
        \centering
        \includegraphics[width=\textwidth]{loudness}
        \caption{Histogram dla cechy \textit{loudness} (pl. głośność).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:year}
        \centering
        \includegraphics[width=\textwidth]{year}
        \caption{Histogram dla cechy \textit{year} (pl. rok publikacji).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:speechiness}
        \centering
        \includegraphics[width=\textwidth]{speechiness}
        \caption{Histogram dla cechy \textit{speechiness} (pl. wypełnienie mową).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:tempo}
        \centering
        \includegraphics[width=\textwidth]{tempo}
        \caption{Histogram dla cechy \textit{tempo} (pl. tempo).}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:mode}
        \centering
        \includegraphics[width=7cm,keepaspectratio]{mode}
        \caption{Wykres kołowy pokazujący procentowy rozkład dominant dla badanych utworów.}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:explicit}
        \centering
        \includegraphics[width=7cm,keepaspectratio]{explicit}
        \caption{Wykres kołowy pokazujący procentowy udział utworów zawierających treści przeznaczone dla odbiorców pełnoletnich.}
    \end{figure}

    \smallskip

    \begin{figure}[H]
        \label{fig:key}
        \centering
        \includegraphics[width=10cm,keepaspectratio]{key}
        \caption{Wykres kołowy pokazujący procentowy rozkład tonacji dla badanych utworów.}
    \end{figure}


    \section{Zastosowanie dwustopniowego algorytmu uczenia maszynowego do predykcji popularności utworu}

    \subsection{Wstępna obróbka danych}

    % do poprawy i rozszerzenia!!!
    Do stworzenia modeli wykorzystano następujące parametry: \textit{valence}, \textit{acousticness}, \textit{danceability}, \textit{duration\_ms}, \textit{energy}, \textit{explicit}, \textit{instrumentalness}, \textit{key}, \textit{liveness}, \textit{loudness}, \textit{mode}, \textit{release\_date}, \textit{speechiness} i \textit{tempo} Trzeba tu nadmienić, że na potrzeby dalszych działań wartości parametru \textit{key} zostały zamienione na binarną postać wektorową (ang. \textit{one-hot encoding}), a wartości \textit{release\_date} na milisekundy w standardzie UNIX. Na podstawie wartości wcześniej wymienionych parametrów modele szacowały wartość popularności (ang. \textit{popularity}) utworu.

    \subsection{Ogólny zarys architektury zastosowanej sieci neuronowej}

    \subsection{Inicjacja wag funkcją HE}

    Podczas badań nad procesem uczenia głębokich sieci neuronowych badacze natrafili na tak zwany `problem zanikających gradientów' (malenie wartości gradientów funkcji kosztu wraz z propagacją wsteczną na coraz niższe warstwy sieci) oraz będący jego przeciwieństwem `problem wybuchających gradientów' (stały wzrost gradientów powodujący rozbieżność algorytmu, problem dotyczący głównie rekurencyjnych sieci neuronowych)\cite{UczenieMaszynowe2018}. Była to przeszkoda na tyle poważna, że na długie lata wstrzymała rozwój prac nad głębokimi sieciami neuronowymi. Dopiero w 2010 roku Xavier Glorot i Yoshua Benglo udało się zdiagnozować przyczynę problemu i zaproponować skuteczne rozwiązanie. Przyczyną okazało się być powszechne wykorzystywanie kombinacji logistycznej i sigmoidalnej funkcji aktywacji oraz inicjacji wag losowymi wartościami o rozkładzie normalnym i średniej równej 0 oraz odchyleniu standardowym równym 1. Badacze doszli do wniosku, że prawidłowy przepływ informacji między warstwami sieci jest możliwy jedynie gdy wariancja dla wyjść warstwy jest równa wariancji wejść tejże, a także gradienty funkcji kosztu muszą mieć taką samą wariancję przed i po przejściu przez daną warstwę w procesie propagacji wstecznej\cite{UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks2010}.

    \bigskip

    Wzory dla inicjacji Xaviera (Glorot), dla logistycznej funkcji aktywacji przedstawiają się następująco:

    \bigskip

    Odchylenie standardowe dla rozkładu normalnego o średniej 0: \\
    \begin{equation}
        \label{equ:std_dev_xavier}
        \sigma = \sqrt{\frac{2}{n_{input} + n_{output}}}
    \end{equation}

    \smallskip

    Promień dla rozkładu jednorodnego (gdzie wartości mieszczą się w przedziale $\langle$-r,r$\rangle$): \\
    \begin{equation}
        \label{equ:radius_xavier}
        r = \sqrt{\frac{6}{n_{input} + n_{output}}}
    \end{equation}

    \smallskip

    \begin{tabular}{p{0.08\textwidth}p{0.92\textwidth}}
        Gdzie: \\
        $n_{input}$  & liczba połączeń wejściowych w warstwie \\
        $n_{output}$ & liczba połączeń wyjściowych w warstwie \\
    \end{tabular}

    \bigskip

    Zaproponowana przez Glorot i Benglo metoda inicjacji wag sprawdzała się świetnie w połączeniu z logistyczną funkcją aktywacji. W przypadku zastosowania jej w połączeniu z funkcją aktywacji ReLU (a także jej odmianami takimi jak ELU) wyniki były niezadowalające. Kolejnego przełomu udało się dokonać w 2015 roku Kaiming He wraz zespołem współpracowników z Microsoft Research w wyniku prac nad klasyfikatorem dla zbioru ImageNet\cite{DelvingDeepIntoRectifiers2015}. Inicjacja He w odróżnieniu od inicjacji Xaviera (Glorot) uwzględnia jedynie obciążalność wejściową warstwy (a nie jak u poprzednika średnią obciążalności wejściowej i wyjściowej)\cite{UczenieMaszynowe2018}.

    \bigskip

    Wzór na odchylenie standardowe w inicjacji He dla rozkładu normalnego o średniej 0: \\
    \begin{equation}
        \label{equ:std_dev_he}
        \sigma = \sqrt{\frac{2}{n_{input}}}
    \end{equation}

    \smallskip

    \begin{tabular}{p{0.08\textwidth}p{0.92\textwidth}}
        Gdzie: \\
        $n_{input}$ & liczba połączeń wejściowych w warstwie \\
    \end{tabular}

    \subsection{Funkcja aktywacji ELU}

    Początkowo uważano, że najlepsze jako funkcje aktywacji będą funkcje sigmoidalne. Przekonanie to brało się stąd, że podobnymi funkcjami można opisać przetwarzanie sygnału przez neurony biologiczne. To intuicyjne skojarzenie okazało się jednak mylne. Po pewnym czasie odkryto, że o wiele lepiej do tego celu nadaje się funkcja ReLU(ang. \textit{Rectified Linear Unit} pl. prosta liniowa funkcja aktywacji)\cite{UczenieMaszynowe2018}. Głównymi zaletami funkcji ReLU są:
    \begin{itemize}
        \item nie uleganie nasyceniu dla wartości dodatnich
        \item ma bardzo niski koszt obliczeniowy
    \end{itemize}

    \bigskip

    Wzór dla funkcji aktywacji ReLU: \\
    \begin{equation}
        \label{equ:relu}
        ReLU(x) =
        \begin{cases}
            0 & \quad \text{jeśli } x < 0 \\
            x & \quad \text{jeśli } x \geq 0
        \end{cases}
    \end{equation}

    \bigskip

    \begin{figure}[H]
        \label{fig:relu}
        \centering
        \includegraphics[width=\textwidth]{relu}
        \caption{Wykres funkcji ReLU.}
    \end{figure}

    \bigskip

    Funkcja ReLU ma jednak ogromną wadę, potocznie nazywaną `śmiercią ReLU' - polega to na tym, że w procesie uczenia niektóre neurony trwale `giną', to znaczy, że zaczynają przesyłać wyłącznie sygnał 0 i nie ma możliwości, żeby `zmartwychwstały'\cite{UczenieMaszynowe2018}. Z tego też powodu w praktyce stosowane są obecnie modyfikacje funkcji ReLU, z pośród który najpopularniejsze to:
    \begin{itemize}
        \item `przeciekająca' funkcja ReLU
        \item losowa `przeciekająca' funkcja ReLU
        \item parametryczna `przeciekająca' funkcja ReLU
        \item ELU (ang. \textit{exponential linear unit} pl. jednostka wykładniczo liniowa)
    \end{itemize}

    \bigskip

    W 2015 roku Djork-Arné Clevert wraz z zespołem odkrył nową funkcję aktywacji - ELU\cite{FastAndAccurateDeepNetworkLearningByELU2016}. Po przeprowadzonych eksperymentach okazało się, że góruje ona zarówno nad tradycyjną funkcją ReLU, jak i jej modyfikacjami. Umożliwiała skrócenie procesu uczenia, a także przyczyniła się wydatnie do poprawy wyników dla zbioru testowego\cite{UczenieMaszynowe2018}. Główne zalety ELU w zestawieniu z ReLU to:
    \begin{itemize}
        \item rozwiązanie `problemu zanikających gradientów' dzięki przyjmowaniu ujemnych wartości dla x < 0
        \item rozwiązanie problemu `umierających neuronów' dzięki niezerowemu gradientowi dla x < 0
        \item przyspieszenie procesu uczenia metodą gradientu prostego dzięki gładkości funkcji na cały przebiegu
    \end{itemize}

    \smallskip

    Wadą jest natomiast niewątpliwie większy koszt obliczeniowy w porównaniu z ReLU spowodowany obecnością składowej wykładniczej.

    \bigskip

    Wzór dla funkcji aktywacji ELU: \\
    \begin{equation}
        \label{equ:elu}
        ELU_{\alpha}(x) =
        \begin{cases}
            \alpha(\exp(x)-1) & \quad \text{jeśli } x < 0 \\
            x & \quad \text{jeśli } x \geq 0
        \end{cases}
    \end{equation}

    \smallskip

    \begin{tabular}{p{0.08\textwidth}p{0.92\textwidth}}
        Gdzie: \\
        $\alpha$ & hiperparametr definiujący wartość do jakiej ma się zbliżać funkcja dla ujemnych wartości x \\
    \end{tabular}

    \bigskip

    \begin{figure}[H]
        \label{fig:elu}
        \centering
        \includegraphics[width=\textwidth]{elu}
        \caption{Wykres funkcji ELU dla $\alpha$=1.}
    \end{figure}

    \subsection{Normalizacja wsadowa (ang. \textit{Batch Normalization})}

    Zastosowanie kombinacji inicjacji He w połączeniu z funkcją aktywacji ELU nie rozwiązało całkowicie problemu zanikających i eksplodujących gradientów. Problem nadal występował na dalszych etapach procesu uczenia. Dopiero zaproponowane w 2015 roku przez Sergeya Ioffe i Christiana Szegedy rozwiązanie - normalizacja wsadowa (ang. \textit{Batch Normalization}), w połączeniu z wcześniej wymienionymi pozwoliło ostatecznie pokonać trudność\cite{BatchNormalization2015}.

    \bigskip

    Operację normalizacji wsadowej wykonuje się na każdej warstwie bezpośrednio przed funkcją aktywacji. Najpierw wyśrodkowuje się i normalizuje się dane wyjściowe. Następnie przeskalowuje się i przesuwa się wyniki za pomocą dwóch parametrów wyliczanych dla każdej warstwy ($\gamma$ - parametr skalowania, $\beta$ - parametr przesunięcia)\cite{UczenieMaszynowe2018}.

    \bigskip

    Normalizacja wsadowa danych wejściowych dla pojedynczej warstwy:

    \bigskip

    Wyliczenie średniej dla minigrupy: \\
    \begin{equation}
        \label{equ:minibatch_mean}
        \mu_{B} = \frac{1}{m_{B}} \displaystyle\sum_{i=1}^{m_{B}} x^{(i)}
    \end{equation}

    \smallskip

    Wyliczenie odchylenia standardowego dla minigrupy: \\
    \begin{equation}
        \label{equ:minibatch_std_dev}
        \sigma_{B}^{2} = \frac{1}{m_{B}} \displaystyle\sum_{i=1}^{m_{B}} (x^{(i)} - \mu_{B})^{2}
    \end{equation}

    \smallskip

    Wyśrodkowanie i znormalizowanie danych wejściowych: \\
    \begin{equation}
        \label{equ:centering_and_normalizing_input}
        \widehat{x}^{(i)} = \frac{x^{(i)} - \mu_{B}}{\sqrt{\sigma_{B}^{2} + \epsilon}}
    \end{equation}

    \smallskip

    Przeskalowanie i przesunięcie wyniku: \\
    \begin{equation}
        \label{equ:rescaling_and_translating_result}
        z^{(i)} = \gamma\widehat{x}^{(i)} + \beta
    \end{equation}

    \smallskip

    \begin{tabular}{p{0.08\textwidth}p{0.92\textwidth}}
        Gdzie: \\
        $\mu_{B}$           & średnia empiryczna wyliczona dla całej minigrupy B                                                                                                                \\
        $\sigma_{B}$        & empiryczne odchylenie standardowe wyliczone dla całej minigrupy B                                                                                                 \\
        $m_{B}$             & liczba przykładów w minigrupie                                                                                                                                    \\
        $\widehat{x}^{(i)}$ & wyśrodkowane i znormalizowane dane wejściowe                                                                                                                      \\
        $\gamma$            & parametr skalowania w danej warstwie                                                                                                                              \\
        $\beta$             & parametr przesunięcia w danej warstwie                                                                                                                            \\
        $\epsilon$          & niewielka liczba służąca do uniknięcia operacji dzielenia przez 0 (zazwyczaj ma wartość $10^{-5}$; jest to tzw, człon wygładzający (ang. \textit{smoothing term}) \\
        $z^{(i)}$           & wynik operacji normalizacji wsadowej: przeskalowana i przesunięta wersja danych wejściowych                                                                       \\
    \end{tabular}

    \bigskip

    Główne zalety normalizacji wsadowej to\cite{UczenieMaszynowe2018}:
    \begin{itemize}
        \item ograniczenie `problemu zanikających gradientów' w stopniu pozwalającym na używanie nasycających funkcji aktywacji takich jak tangens hiperboliczny
        \item zmniejszenie wrażliwości sieci na inicjację wag
        \item umożliwienie wykorzystywania większej wartości współczynnika uczenia, a co za tym idzie znaczne przyspieszenie całego procesu uczenia
        \item poprawa wyników dla zagadnień klasyfikacji i regresji
        \item częściowe spełnianie roli regularyzatora
    \end{itemize}

    \bigskip

    Największe wady to\cite{UczenieMaszynowe2018}:
    \begin{itemize}
        \item zwiększenie skomplikowania modelu
        \item spowolnienie działania modelu ze względu na konieczność przeprowadzenia dodatkowych obliczeń dla każdej warstwy (spowalnia to w szczególności początek procesu uczenia, gdyż algorytm gradientu prostego wyszukuje optymalne skale i przesunięcia dla każdej warstwy, następnie proces przyspiesza)
    \end{itemize}

    \subsection{Regularyzacja przez Porzucanie (ang. \textit{Dropout})}

    Pierwotny pomysł zastosowania techniki `porzucania' jako sposobu na regularyzację głębokiej sieci neuronowej powstał w 2012 roku. Jego autorem był pracujący na Uniwersytecie Toronto G.E. Hinton (wraz ze współpracownikami). Wyniki swoich badań zaprezentował w artykule ``Improving neural networks by preventing co-adaptation of feature detectors''\cite{ImprovingNeuralNetworks2012}. Jego dzieło rozwinął działający na tej samej uczelni Nitish Srivastava (ze swoim zespołem), a rezultaty opublikował w 2014 roku w artykule ``Dropout: A Simple Way to Prevent Neural Networks from Overfitting''\cite{Dropout2014}. Osiągane rezultaty były imponujące - zwiększenie dokładności klasyfikatorów o 1-2\% co przekładało się na nawet kilkudziesięciu procentowe zmniejszenie współczynnika błędu.

    \bigskip

    Algorytm jest bardzo prosty. Podczas każdego przebiegu procesu uczenia dowolny neuron, za wyjątkiem neuronów warstwy wyjściowej, może zostać `porzucony', to znaczy całkowicie pominięty w procesie uczenia, z ustalonym z góry prawdopodobieństwem \textit{p}. Następnie już po zakończeniu treningu konieczne jest przemożenie każdej wagi połączenia wejściowego przez tak zwane `prawdopodobieństwo utrzymania' (ang. \textit{keep probability}) równe 1 - \textit{p}. Alternatywą jest podzielenie wartości wejścia każdego neuronu przez `prawdopodobieństwo utrzymania' w trakcie nauki\cite{UczenieMaszynowe2018}.

    \bigskip

    W praktyce dla każdej `epoki' mamy do czynienia z unikalną siecią. Istnieje $2^{N}$ możliwych kombinacji gdzie N oznacza całkowitą liczbę neuronów, które mogą zostać porzucone. Te sztucznie pomniejszone sieci są wobec siebie całkowicie niezależne. Finalna sieć jest pewnym rodzajem uśrednienia\cite{UczenieMaszynowe2018}.

    \bigskip

    Podsumowując, główne korzyści płynące z zastosowania techniki `porzucania' to\cite{UczenieMaszynowe2018}:
    \begin{itemize}
        \item uczone neurony nie mogą uzależniać się od swoich sąsiadów; same muszą wnosić jak najwięcej `wartości dodanej' przy przetwarzaniu sygnału; muszą skupiać się na poszczególnych wejściach, a nie traktować ich kombinacji całościowo
        \item wynikające z powyższego zmniejszenie wrażliwości na drobne zmiany na wejściach
        \item patrząc całościowo uzyskany w wyniku `porzucania' model jest lepszą generalizacją
    \end{itemize}

    \smallskip

    Główną wadą jest spowolnienie procesu konwergencji modelu\cite{UczenieMaszynowe2018}.

    \bigskip

    Bardzo ważny jest prawidłowy dobór `współczynnika porzucania' tak, żeby uniknąć zarówno niedotrenowania (zbyt duża wartość) jak i przetrenowania (zbyt mała wartość). Cenną wskazówką jest zastosowanie większej wartości współczynnika dla rozbudowanych warstw, a mniejszej dla niewielkich.

    \bigskip

    \begin{figure}[H]
        \label{fig:dropout}
        \centering
        \includegraphics[width=\textwidth]{dropout}
        \caption{Regularyzacja przez `porzucanie'\cite{UczenieMaszynowe2018}.}
    \end{figure}

    \subsection{Optymalizator Adam}

    Optymalizatory są kolejnym elementem wprowadzonym w celu przyspieszenia procesu uczenia głębokich sieci neuronowych. Są one bardziej efektywne od standardowego algorytmu gradientu prostego. W praktyce, ze względu na koszty pamięciowe, wykorzystuje się jedynie optymalizatory bazujące na pochodnych cząstkowych pierwszego rzędu (jakobinach)\cite{UczenieMaszynowe2018}. Najpopularniejsze z nich to:
    \begin{itemize}
        \item optymalizacja momentum (ang. \textit{Momentum Optimization})
        \item przyspieszony spadek wzdłuż gradienku (algorytm Nesterova)
        \item AdaGrad (ang. \textit{Adaptive Subgradient Method})
        \item RMSProp
        \item Adam (ang. \textit{Adaptive Moment Estimation})
    \end{itemize}

    \bigskip

    Algorytm Adam został opracowany w 2015 roku przez Diederik P. Kingma i Jimmy Lei Ba\cite{AdamOptimization2015}. Jest połączeniem pomysłów wykorzystanych w optymalizacji momentum i optymalizatorze RMSProp. Z optymalizacji momentum zaczerpnięte jest śledzenie rozkładu wykładniczego średniej wcześniejszych gradientów, a z RMSProp - śledzenie rozkładu wykładniczego średniej wcześniejszych kwadratómomentów\cite{UczenieMaszynowe2018}. Poniżej przedstawiono pseudokod z oryginalnej publikacji Kingma i Ba.

    \bigskip

    \begin{algorithm}[H]
        \label{alg:adam_optimizer}
        \caption{Algorytm Adam. Źródło:\cite{AdamOptimization2015}.}
        \begin{algorithmic}
            \Require $\alpha$
            \Comment{współczynnik uczenia, który zazwyczaj inicjowany jest wartością $\alpha = 0.001$}
            \Require $\beta_{1},\beta_{2} \in (0,1]$
            \Comment{$\beta_{1}$ to hiperparametr rozkładu momentu, który zazwyczaj inicjowany wartością $\beta_{1} = 0.9$; $\beta_{2}$ to hiperparametr rozkładu skalowania, który zazwyczaj inicjowany wartością $\beta_{2} = 0.999$}
            \Require $\epsilon$
            \Comment{człon wygładzający, który zazwyczaj przyjmuje wartość $\epsilon = 10^{-8}$}
            \Require $f(\theta)$
            \Comment{funkcja stochastyczna $f$ z wektorem parametrów $\theta$}
            \Require $\theta_{0}$
            \Comment{postać początkowa wektora parametrów $\theta$}
            \State $m_{0} \gets 0$
            \Comment{inicjacja pierwszego wektora momentu}
            \State $v_{0} \gets 0$
            \Comment{inicjacja drugiego wektora momentu}
            \State $t \gets 0$
            \Comment{inicjacja licznika przebiegów}
            \While{$\theta_{t}$ nie zbiegnie}
                \State $t \gets t + 1$
                \State $g_{t} \gets \nabla_{\theta}f_{t}(\theta_{t-1})$
                \Comment{uzyskanie gradientów dla stochastycznej funkcji kosztu w przebiegu $t$}
                \State $m_{t} \gets \beta_{1} \cdot m_{t-1} + (1 - \beta_{1}) \cdot g_{t}$
                \Comment{aktualizacja szacunkowej wartości pierwszego wektora momentu}
                \State $v_{t} \gets \beta_{2} \cdot v_{t-1} + (1 - \beta_{2}) \cdot g_{t}^{2}$
                \Comment{aktualizacja szacunkowej wartości drugiego wektora momentu}
                \State $\widehat{m_{t}} \gets \frac{m_{t}}{1 - \beta_{1}^{t}}$
                \Comment{obliczenie szacunkowkowej wartości pierwszego wektora momentu}
                \State $\widehat{v_{t}} \gets \frac{v_{t}}{1 - \beta_{2}^{t}}$
                \Comment{obliczenie szacunkowkowej wartości drugiego wektora momentu}
                \State $\theta_{t} \gets \theta_{t-1} - \frac{\alpha \cdot \widehat{m_{t}}}{\sqrt{\widehat{v_{t}}} + \epsilon}$
                \Comment{aktualizacja wektora parametrów}
            \EndWhile
            \State \Return $\theta_{t}$
            \Comment{wynikowy wektor parametrów}
        \end{algorithmic}
    \end{algorithm}

    \bigskip

    Optymalizator Adam, podobnie jak RMSProp, wykorzystuje adaptacyjny współczynnik uczenia. Z tego też powodu nie ma koniczności wyznaczania jego optymalnej wartości, wystarczy jedynie skorzystać z domyślnej wartości $\alpha = 0.001$\cite{UczenieMaszynowe2018}. To z kolei sprawia, że Adam jest w praktyce prostszy w użyciu od metody gradientu prostego.

    \subsection{Wybór hiperparametrów procesu uczenia sieci neuronowej}

    \subsection{Wybór rodziców z wykorzystaniem selekcji proporcjonalnej (ang. \textit{Fitness Proportionate Selection / FPS})}

    Selekcja proporcjonalna (ang. \textit{Fitness Proportionate Selection / FPS}) lub inaczej selekcja ruletkowa (ang. \textit{Roulette Wheel Selection}) jest popularną metodą wykorzystywaną do wyboru odpowiednich osobników (rodziców) do rekombinacji (krzyżowania). Autorem oryginalnego konceptu był J.H Holland z Massachusetts Institute of Technology. Selekcja polega na losowaniu osobnika z prawdopodobieństwem równym stosunkowi absolutnej wartości jego metryki dopasowania (ang. \textit{fitness}) $f_{i}$ do sumy wartości absolutnych metryk dopasowań dla całej populacji $\sum_{j=1}^{\mu} f_{j}$\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    Wzór na prawdopodobieństwo wylosowania pojedynczego osobnika prezentuje się następująco: \\
    \begin{equation}
        \label{equ:fitness_proportionate_selection}
        P_{FPS}(i) = \frac{\lvert f_{i} \rvert}{\sum_{j=1}^{\mu} \lvert f_{j} \rvert}
    \end{equation}

    \bigskip

    \begin{figure}[H]
        \label{fig:proportional_selection}
        \centering
        \includegraphics[width=\textwidth]{proportional_selection}
        \caption{Obrazowy przykład działania selekcji proporcjonalnej.}
    \end{figure}

    \bigskip

    Okazało się, że selekcja proporcjonalna wyjątkowo dobrze nadaje się do analizy teoretycznej. Niestety bardzo szybko odkryto też jej główne mankamenty\cite{IntroductionToEvolutionaryComputing2015}:
    \begin{itemize}
        \item Najlepsze osobniki bardzo szybko przejmują `kontrolę' nad populacją. To powoduje, że zostaje bardzo zawężony obszar poszukiwań najlepszego rozwiązania, a prawdopodobieństwo uzyskania dobrego wyniku jest nikłe. Problem uwidacznia się zwłaszcza we wczesnych generacjach, kiedy wiele losowo utworzonych osobników ma niską wartość metryki dopasowania (ang. \textit{fitness}). Fachowo określa się to terminem przedwczesnej konwergencji (zbiegnięcia) (ang. \textit{premature convergence}).
        \item Kiedy wartości metryki dopasowania są zbliżone do siebie zanika tak zwana `presja selekcyjna' (ang. \textit{selection pressure}). Rezultatem jest niemal losowa selekcja w kolejnych pokoleniach (generacjach) i bardzo powolna konwergencja (zbieganie) do optymalnego rozwiązania.
    \end{itemize}

    \bigskip

    Na szczęście opracowane zostały skuteczne techniki zaradcze. Najpopularniejsze to:
    \begin{itemize}
        \item `okienkowanie' (ang. \textit{windowing})
        \item skalowanie sigma (ang. \textit{sigma scaling})
    \end{itemize}

    \bigskip

    `Okienkowanie' (ang. \textit{windowing}), z którego skorzystano w ramach niniejszej pracy, polega na odejmowaniu od pierwotnej wartości metryki dopasowania  $f_{i}$ wartości $\beta^{t}$ zależnej od przebiegu działania algorytmu i zmiennej w czasie. Przeważnie jest to najmniejsza (lub najgorsza) wartość metryki dopasowania dla całej populacji z kilku wcześniejszych pokoleń\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    \begin{equation}
        \label{equ:new_fitness}
        f'(i) = f(i) - \beta^{t}
    \end{equation}

    \subsection{Krzyżówka z jednym punktem przecięcia (ang. \textit{One Point Crossover})}

    Krzyżówka z jednym punktem przecięcia (ang. \textit{One Point Crossover}) polega na wyznaczeniu losowego punktu, przez który dzieli się następnie chromosomy rodziców, a z otrzymanych części buduje się finalnie chromosomy potomków. Przykładowo, jeśli chromosomy mają postać ciągów bitowych, pierwszy rodzic to 0010110010, drugi rodzic to 1111010111 a punkt przecięcia został wyznaczony na 4, to w wyniku operacji krzyżowania otrzymamy następujących potomków: 0010110010 i 1111110010\cite{GeneticAlgorithmEssentials2017}.

    \bigskip

    \begin{figure}[H]
        \label{fig:one_point_crossover}
        \centering
        \includegraphics[width=\textwidth]{one_point_crossover}
        \caption{Obrazowy przykład działania krzyżowania z jednym punktem przecięcia.}
    \end{figure}

    \subsection{Mutacja pełzająca (ang. \textit{Creep Mutation}), niejednorodna (ang. \textit{nonuniform})}

    Mutacja pełzająca (ang. \textit{Creep Mutation}) jest często stosowanym rozwiązaniem dla allelów (parametrów) typu \textit{integer} (całkowitych) lub \textit{float} (zmienno-przecinkowych). Polega ona na translacji pierwotnej wartości allelu poprzez dodanie niewielkiej (dotatniej lub ujemnej) liczby losowej, tak by rezult mieścił się w granicach $x_{i}^{'} \in [L_{i}, U_{i}]$\cite{IntroductionToEvolutionaryComputing2015}.

    \bigskip

    Transformaca wartości parametów osobnika w ramach mutacji: \\
    \begin{equation}
        \label{equ:mutation_transformation}
        \langle x_{1},\dotsc,x_{n}> \rangle \to \langle x_{1}^{'},\dotsc,x_{n}^{'} \rangle \quad \text{gdzie } x_{i}, x_{i}^{'} \in [L_{i}, U_{i}]
    \end{equation}

    \smallskip

    \begin{tabular}{p{0.08\textwidth}p{0.92\textwidth}}
        Gdzie: \\
        $L_{i}$ & dolna granica dla transformacji \\
        $U_{i}$ & górna granica dla transformacji \\
    \end{tabular}

    \bigskip

    Stosować można zarówno mutację jednorodną (ang. \textit{Uniform Mutation}) - opartą o liczby losowe wygenerowane wegług rozkładu jednorodnego, jak i mutację niejednorodną (ang. \textit{Nonuniform Mutation}) - opartą o rozkład Gaussa (rzadziej o rozkład Cauchego)\cite{IntroductionToEvolutionaryComputing2015}. W przypadku niniejszej pracy zdecydowano się na generowanie przesunięć ($\Delta x_{i}$) w oparciu o rozkład Gaussa, a następnie na ograniczanie wyliczonych nowych wartości parametów do z góry wyznaczonych granic ($L_{i}, U_{i}$). Do sterowania losowością przesunięć stosuje się odchylenie standardowe $\sigma$, tu określane jako `miara kroku mutacji' (ang. \textit{mutation step size}). Dla niniejszej pracy przyjęto, ze względu na przebieg funkcji gęstości prawdopodobieństwa dla rozkładu Gaussa, $\sigma = (U_{i} - L_{i}) / 6$.

    \bigskip

    Funkcja gęstości prawdopodobieństwa dla rokładu Gaussa: \\
    \begin{equation}
        \label{equ:mutation_probabily distribution}
        p(\Delta x_{i}) = \frac{1}{\sigma \sqrt {2 \pi}} \cdot e \frac{(\Delta x_{i} - \xi)^{2}}{2 \sigma^{2}}
    \end{equation}

    \bigskip

    \begin{figure}[H]
        \label{fig:standard_deviation_diagram}
        \centering
        \includegraphics[width=\textwidth]{standard_deviation_diagram}
        \caption{Wykres dla rozkładu Gaussa. Jednostka dla osi \textit{x} to odchylenie standardowe ($\sigma$). W odległości $1 \cdot \sigma$ od średniej znajduje się 68.27\% elementów; w odległości $2 \cdot \sigma$ - 95.45\% elementów; w odległości $3 \cdot \sigma$ - 99.73\% elementów. Autor: M.W. Toews (Wikipedia Community).}
    \end{figure}


    \section{Rezultaty eksperymentów}
    % algorytm genetyczny historia:  poprawy błędu w czasie dla najlepszego
    % algorytm genetyczny historia:  poprawy błędu w czasie średnia
    % zrzuty architektury sieci z tensorboard
    % porównianie sieci inicjowanej na sztywno i sieci z hiperparamertami wyuczonymi


    \section{Wnioski}
    % przanalizować dla jakich utworów szacowało najlepiej, a dla jakich najgorzej
    % napisać wnioski jakich informacji zabrakło i co można by zrobić lepiej


    \printbibliography

\end{document}